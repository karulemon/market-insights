{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ec0a9476-abf5-41e9-80fc-89854dc5e941",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter market topic to research:  cred rewards\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Reddit posts on: cred rewards\n",
      "\n",
      "📊 Reddit Sentiment Summary:\n",
      "- Average sentiment: 0.03\n",
      "- Top Insights:\n",
      "  - (0.10) Album of the Year: Kendrick Lamar - GNX...\n",
      "  - (-0.50) Random person at the bank this morning....\n",
      "  - (-0.05) DE, pls allow people who have already gotten the past repeat rewards to at least get nightwave cred....\n",
      "  - (0.32) Another CRED Post: How CRED Rewards really work on the inside...\n",
      "  - (0.07) Maxed Skills, Tier 5 Cyberware, and Over $1M Eddies… in the Prologue. Am I Doing This Right?...\n",
      "  - (0.06) The Sun Never Sets on Citadel -- Part 4...\n",
      "  - (0.07) Nightwave Vol. 8 coming out...\n",
      "  - (0.69) CRED be like: “Rewarding you… with what you already have!”...\n",
      "  - (-0.03) How to get rid of those gambling ad banners from reward section of cred...\n",
      "  - (-0.40) After just announcing the board game crowdfunding, the goal is already 1497% funded. ...\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import json\n",
    "import praw\n",
    "from newsapi import NewsApiClient\n",
    "from textblob import TextBlob\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# ----------- API KEYS AND CONFIG -----------\n",
    "REDDIT_CLIENT_ID = \"V8W1O2VI7wiZ1tv96LnzTg\"\n",
    "REDDIT_SECRET = \"vlp_w9v35P-29qm-MxpyMxFB3D_mrA\"\n",
    "REDDIT_USER_AGENT = \"PiggyLime's Market Bot\"\n",
    "\n",
    "#NEWS_API_KEY = 'your_newsapi_key'\n",
    "\n",
    "# ----------- INIT APIS -----------\n",
    "reddit = praw.Reddit(\n",
    "    client_id=\"V8W1O2VI7wiZ1tv96LnzTg\",\n",
    "    client_secret=\"vlp_w9v35P-29qm-MxpyMxFB3D_mrA\",\n",
    "    user_agent=\"PiggyLime's Market Bot\"\n",
    ")\n",
    "\n",
    "#newsapi = NewsApiClient(api_key=NEWS_API_KEY)\n",
    "\n",
    "# ----------- CORE FUNCTIONS -----------\n",
    "\n",
    "def analyze_sentiment(text):\n",
    "    blob = TextBlob(text)\n",
    "    return blob.sentiment.polarity  # float between -1 and 1\n",
    "\n",
    "def fetch_tweets_cli(keyword, limit=20):\n",
    "    print(f\"\\n🔍 Tweets on: {keyword}\")\n",
    "    tweets = []\n",
    "    try:\n",
    "        command = f\"snscrape --max-results {limit} --jsonl twitter-search '{keyword} lang:en'\"\n",
    "        result = subprocess.run(command, shell=True, capture_output=True, text=True)\n",
    "        for line in result.stdout.strip().split('\\n'):\n",
    "            tweet = json.loads(line)\n",
    "            content = tweet.get(\"content\", \"\")\n",
    "            sentiment = analyze_sentiment(content)\n",
    "            tweets.append((content, sentiment))\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching tweets: {e}\")\n",
    "    return tweets\n",
    "\n",
    "def fetch_reddit(keyword, limit=10):\n",
    "    print(f\"\\n🔍 Reddit posts on: {keyword}\")\n",
    "    posts = []\n",
    "    try:\n",
    "        for submission in reddit.subreddit(\"all\").search(keyword, limit=limit):\n",
    "            content = submission.title + \" \" + submission.selftext\n",
    "            sentiment = analyze_sentiment(content)\n",
    "            posts.append((submission.title, sentiment))\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching Reddit posts: {e}\")\n",
    "    return posts\n",
    "\n",
    "def fetch_news(keyword, days=3):\n",
    "    print(f\"\\n🔍 News articles on: {keyword}\")\n",
    "    news_data = []\n",
    "    try:\n",
    "        from_date = (datetime.now() - timedelta(days=days)).strftime('%Y-%m-%d')\n",
    "        articles = newsapi.get_everything(q=keyword, from_param=from_date, language='en', sort_by='relevancy', page_size=10)\n",
    "        for article in articles['articles']:\n",
    "            content = article['title'] + ' ' + (article['description'] or '')\n",
    "            sentiment = analyze_sentiment(content)\n",
    "            news_data.append((article['title'], sentiment))\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching news: {e}\")\n",
    "    return news_data\n",
    "\n",
    "def summarize_insights(data, source):\n",
    "    total_sentiment = sum(s for _, s in data)\n",
    "    avg_sentiment = total_sentiment / len(data) if data else 0\n",
    "    print(f\"\\n📊 {source} Sentiment Summary:\")\n",
    "    print(f\"- Average sentiment: {avg_sentiment:.2f}\")\n",
    "    print(\"- Top Insights:\")\n",
    "    for text, sentiment in data[:10]:\n",
    "        print(f\"  - ({sentiment:.2f}) {text[:100]}...\")\n",
    "\n",
    "# ----------- MAIN WORKFLOW -----------\n",
    "\n",
    "def get_market_insights(query):\n",
    "    #tweets = fetch_tweets_cli(query)\n",
    "    reddit_posts = fetch_reddit(query)\n",
    "    #news_articles = fetch_news(query)\n",
    "\n",
    "    #summarize_insights(tweets, \"Twitter\")\n",
    "    summarize_insights(reddit_posts, \"Reddit\")\n",
    "    #summarize_insights(news_articles, \"News\")\n",
    "\n",
    "# ----------- Run Example -----------\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    user_query = input(\"Enter market topic to research: \")\n",
    "    get_market_insights(user_query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b665591b-ded3-46ef-a215-cfe63a570445",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 MARKET SENTIMENT ANALYZER 🚀\n",
      "-----------------------------------\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter market topic to research:  ipl\n",
      "Filter by date range? (y/n):  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔎 Researching market insights for: 'ipl'\n",
      "\n",
      "🔍 Reddit posts on: ipl\n",
      "📅 Time range: Past month (default)\n",
      "📬 Searching r/investing...\n",
      "📬 Searching r/stocks...\n",
      "📬 Searching r/wallstreetbets...\n",
      "📬 Searching r/StockMarket...\n",
      "📬 Searching r/ValueInvesting...\n",
      "📬 Searching r/options...\n",
      "📬 Searching r/algotrading...\n",
      "📬 Searching r/SecurityAnalysis...\n",
      "📬 Searching r/InvestmentEducation...\n",
      "📬 Searching r/CreditCardsIndia...\n",
      "📬 Searching r/dividends...\n",
      "📬 Searching r/Daytrading...\n",
      "📬 Searching r/StockMarket...\n",
      "📬 Searching r/pennystocks...\n",
      "📬 Searching r/investing_discussion...\n",
      "📬 Searching r/IndiaInvestments...\n",
      "📬 Searching r/IndianStreetBets...\n",
      "📬 Searching r/IndiaFinance...\n",
      "📬 Searching r/IndianStockMarket...\n",
      "📬 Searching r/CREDclub...\n",
      "📬 Searching r/DalalStreetTalks...\n",
      "📬 Searching r/fiindia...\n",
      "Error in r/fiindia: Redirect to /subreddits/search\n",
      "📬 Searching r/indianbusinessowners...\n",
      "Error in r/indianbusinessowners: Redirect to /subreddits/search\n",
      "📬 Searching r/CREDclub...\n",
      "📬 Searching r/economy...\n",
      "📬 Searching r/Economics...\n",
      "📬 Searching r/finance...\n",
      "📬 Searching r/FinancialIndependence...\n",
      "📬 Searching r/Banking...\n",
      "📬 Searching r/GlobalMarkets...\n",
      "📬 Searching r/econmonitor...\n",
      "📬 Searching r/IndianEconomy...\n",
      "📬 Searching r/supplychain...\n",
      "📬 Searching r/Bitcoin...\n",
      "📬 Searching r/cryptocurrency...\n",
      "📬 Searching r/CryptoMarkets...\n",
      "📬 Searching r/ethtrader...\n",
      "📬 Searching r/CryptoCurrencyTrading...\n",
      "📬 Searching r/CryptoTechnology...\n",
      "📬 Searching r/altcoin...\n",
      "📬 Searching r/defi...\n",
      "📬 Searching r/NFT...\n",
      "📬 Searching r/IndianCryptoMarkets...\n",
      "Error in r/IndianCryptoMarkets: Redirect to /subreddits/search\n",
      "📬 Searching r/tech...\n",
      "📬 Searching r/technology...\n",
      "📬 Searching r/business...\n",
      "📬 Searching r/realestateinvesting...\n",
      "📬 Searching r/Energy...\n",
      "📬 Searching r/startups...\n",
      "📬 Searching r/healthcare...\n",
      "📬 Searching r/retailinvesting...\n",
      "Error in r/retailinvesting: Redirect to /subreddits/search\n",
      "📬 Searching r/AutoIndustry...\n",
      "Error in r/AutoIndustry: received 404 HTTP response\n",
      "📬 Searching r/renewableenergy...\n",
      "📬 Searching r/worldnews...\n",
      "📬 Searching r/news...\n",
      "📬 Searching r/india...\n",
      "📬 Searching r/dataisbeautiful...\n",
      "📬 Searching r/AskEconomics...\n",
      "\n",
      "✅ Processed 18 Reddit posts, found 7 relevant results\n",
      "📅 Posts date range: 2025-03-23 to 2025-04-21\n",
      "🏆 Most active subreddits: r/IndianStreetBets, r/CreditCardsIndia, r/IndianStockMarket\n",
      "\n",
      "============================================================\n",
      "📊 MARKET INSIGHT SUMMARY: 'IPL'\n",
      "============================================================\n",
      "\n",
      "🌡️ SENTIMENT ANALYSIS:\n",
      "- Overall market sentiment: 0.13 [NEUTRAL]\n",
      "- Sentiment trend: ⬇️ DECLINING\n",
      "- Distribution: 3 positive (42.9%), 4 neutral (57.1%), 0 negative (0.0%)\n",
      "\n",
      "🏙️ KEY COMMUNITIES:\n",
      "- r/IndianStreetBets: 2 posts | Sentiment: 0.04\n",
      "- r/CreditCardsIndia: 1 posts | Sentiment: 0.14\n",
      "- r/india: 1 posts | Sentiment: 0.20\n",
      "- r/business: 1 posts | Sentiment: 0.42\n",
      "- r/DalalStreetTalks: 1 posts | Sentiment: 0.04\n",
      "\n",
      "🔑 KEY THEMES & RELATED TERMS:\n",
      "- mail, 2025, being, scripted, betting, highly, successful, much, risk, portfolio\n",
      "\n",
      "🏷️ COMMON POST CATEGORIES:\n",
      "- Help Needed/ Question: 1 posts\n",
      "- Discussion: 1 posts\n",
      "- Sports: 1 posts\n",
      "- Stink: 1 posts\n",
      "- Portfolio Review: 1 posts\n",
      "\n",
      "📈 MARKET ASSESSMENT:\n",
      "- The market appears MIXED/NEUTRAL on this topic\n",
      "- Investors have varied opinions with no strong consensus\n",
      "- Bearish sentiment significantly outweighs bullish views\n",
      "\n",
      "------------------------------------------------------------\n",
      "📝 NOTABLE DISCUSSIONS\n",
      "------------------------------------------------------------\n",
      "\n",
      "🟢 TOP POSITIVE DISCUSSIONS:\n",
      "  1. r/business | 2025-04-12 | ⬆️ 5 | 💬 6 | 😀 0.42\n",
      "     Do highly successful companies that sponsor events actually make any profit?\n",
      "  2. r/india | 2025-04-18 | ⬆️ 90 | 💬 74 | 😀 0.2\n",
      "     Is IPL 2025 being scripted for betting addicts\n",
      "  3. r/CreditCardsIndia | 2025-03-27 | ⬆️ 247 | 💬 13 | 😀 0.14\n",
      "     Got mail that i won IPL tickets.\n",
      "\n",
      "🔴 TOP NEGATIVE DISCUSSIONS:\n",
      "\n",
      "📈 MOST ENGAGING DISCUSSIONS:\n",
      "  1. r/CreditCardsIndia | 2025-03-27 | ⬆️ 247 | 💬 13 | 0.14\n",
      "     Got mail that i won IPL tickets.\n",
      "  2. r/IndianStreetBets | 2025-03-30 | ⬆️ 162 | 💬 12 | 0.04\n",
      "     Conflicted\n",
      "  3. r/india | 2025-04-18 | ⬆️ 90 | 💬 74 | 0.20\n",
      "     Is IPL 2025 being scripted for betting addicts\n",
      "  4. r/IndianStreetBets | 2025-04-02 | ⬆️ 52 | 💬 3 | 0.04\n",
      "     We’ve normalized gambling under the guise of ‘entertainment’.\n",
      "  5. r/business | 2025-04-12 | ⬆️ 5 | 💬 6 | 0.42\n",
      "     Do highly successful companies that sponsor events actually make any profit?\n",
      "\n",
      "============================================================\n",
      "💡 CONCLUSION\n",
      "============================================================\n",
      "The market sentiment on ipl is moderately POSITIVE. Discussions show cautious optimism.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import praw\n",
    "from textblob import TextBlob\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "from collections import Counter\n",
    "\n",
    "# ----------- API KEYS AND CONFIG -----------\n",
    "REDDIT_CLIENT_ID = \"V8W1O2VI7wiZ1tv96LnzTg\"\n",
    "REDDIT_SECRET = \"vlp_w9v35P-29qm-MxpyMxFB3D_mrA\"\n",
    "REDDIT_USER_AGENT = \"PiggyLime's Market Bot\"\n",
    "\n",
    "# ----------- INIT APIS -----------\n",
    "reddit = praw.Reddit(\n",
    "    client_id=REDDIT_CLIENT_ID,\n",
    "    client_secret=REDDIT_SECRET,\n",
    "    user_agent=REDDIT_USER_AGENT\n",
    ")\n",
    "\n",
    "# ----------- SENTIMENT ANALYSIS -----------\n",
    "def analyze_sentiment(text):\n",
    "    \"\"\"Enhanced sentiment analysis with context awareness for financial text\"\"\"\n",
    "    if not text or not isinstance(text, str):\n",
    "        return 0.0\n",
    "    \n",
    "    # Base sentiment from TextBlob\n",
    "    blob = TextBlob(text)\n",
    "    base_sentiment = blob.sentiment.polarity\n",
    "    \n",
    "    # Financial context adjustment - certain phrases have stronger sentiment in finance\n",
    "    financial_boosters = {\n",
    "        'crash': -0.3, 'collapse': -0.3, 'plummet': -0.3, 'tank': -0.25,\n",
    "        'bearish': -0.2, 'sell-off': -0.2, 'downturn': -0.15, 'recession': -0.25,\n",
    "        'bankruptcy': -0.35, 'default': -0.25, 'debt': -0.1, 'inflation': -0.1,\n",
    "        \n",
    "        'bullish': 0.2, 'rally': 0.2, 'surge': 0.25, 'soar': 0.25, \n",
    "        'outperform': 0.2, 'beat': 0.15, 'growth': 0.15, 'profit': 0.2,\n",
    "        'buy': 0.1, 'upgrade': 0.15, 'dividend': 0.15, 'recovery': 0.15\n",
    "    }\n",
    "    \n",
    "    # Check for booster words and adjust sentiment\n",
    "    text_lower = text.lower()\n",
    "    sentiment_adjustment = 0\n",
    "    \n",
    "    for term, value in financial_boosters.items():\n",
    "        if term in text_lower:\n",
    "            sentiment_adjustment += value\n",
    "    \n",
    "    # Adjust sentiment but keep within [-1, 1]\n",
    "    adjusted_sentiment = max(min(base_sentiment + sentiment_adjustment, 1.0), -1.0)\n",
    "    \n",
    "    return adjusted_sentiment\n",
    "\n",
    "# ----------- DATE CONVERSION -----------\n",
    "def convert_time_filter(start_date, end_date):\n",
    "    \"\"\"Convert date range to appropriate Reddit time filter\"\"\"\n",
    "    now = datetime.now()\n",
    "    days_diff = (now - start_date).days\n",
    "    \n",
    "    if days_diff <= 1:\n",
    "        return 'day'\n",
    "    elif days_diff <= 7:\n",
    "        return 'week'\n",
    "    elif days_diff <= 31:\n",
    "        return 'month'\n",
    "    elif days_diff <= 365:\n",
    "        return 'year'\n",
    "    else:\n",
    "        return 'all'\n",
    "\n",
    "# ----------- REDDIT ANALYSIS -----------\n",
    "def fetch_reddit(keyword, start_date=None, end_date=None, limit=15, min_score=2):\n",
    "    \"\"\"\n",
    "    Enhanced Reddit data collection with date filtering\n",
    "    \n",
    "    Args:\n",
    "        keyword (str): Topic to search for\n",
    "        start_date (datetime): Start date for search range\n",
    "        end_date (datetime): End date for search range\n",
    "        limit (int): Maximum posts per subreddit\n",
    "        min_score (int): Minimum upvotes required\n",
    "        \n",
    "    Returns:\n",
    "        list: Processed Reddit posts with sentiment and metadata\n",
    "    \"\"\"\n",
    "    print(f\"\\n🔍 Reddit posts on: {keyword}\")\n",
    "    \n",
    "    # Date range formatting\n",
    "    date_str = \"\"\n",
    "    if start_date and end_date:\n",
    "        date_str = f\" from {start_date.strftime('%Y-%m-%d')} to {end_date.strftime('%Y-%m-%d')}\"\n",
    "        print(f\"📅 Time range:{date_str}\")\n",
    "        time_filter = convert_time_filter(start_date, datetime.now())\n",
    "    else:\n",
    "        time_filter = 'month'  # Default to past month\n",
    "        print(\"📅 Time range: Past month (default)\")\n",
    "    \n",
    "    posts = []\n",
    "    \n",
    "    # Finance and investment focused subreddits + general relevant ones\n",
    "    subreddits = [\n",
    "        # Finance & Investment - Global\n",
    "        \"investing\", \"stocks\", \"wallstreetbets\", \"StockMarket\", \"ValueInvesting\",\n",
    "        \"options\", \"algotrading\", \"SecurityAnalysis\", \"InvestmentEducation\",\"CreditCardsIndia\",\n",
    "        \"dividends\", \"Daytrading\", \"StockMarket\", \"pennystocks\", \"investing_discussion\",\n",
    "        \n",
    "        # Finance & Investment - India\n",
    "        \"IndiaInvestments\", \"IndianStreetBets\", \"IndiaFinance\", \"IndianStockMarket\", \"CREDclub\",\n",
    "        \"DalalStreetTalks\", \"fiindia\", \"indianbusinessowners\", \"CREDclub\",\n",
    "        \n",
    "        # Markets & Economics\n",
    "        \"economy\", \"Economics\", \"finance\", \"FinancialIndependence\", \"Banking\",\n",
    "        \"GlobalMarkets\", \"econmonitor\", \"IndianEconomy\", \"supplychain\",\n",
    "        \n",
    "        # Crypto & Digital Assets\n",
    "        \"Bitcoin\", \"cryptocurrency\", \"CryptoMarkets\", \"ethtrader\", \"CryptoCurrencyTrading\",\n",
    "        \"CryptoTechnology\", \"altcoin\", \"defi\", \"NFT\", \"IndianCryptoMarkets\",\n",
    "        \n",
    "        # Industry specific\n",
    "        \"tech\", \"technology\", \"business\", \"realestateinvesting\", \"Energy\",\n",
    "        \"startups\", \"healthcare\", \"retailinvesting\", \"AutoIndustry\", \"renewableenergy\",\n",
    "        \n",
    "        # General discussion\n",
    "        \"worldnews\", \"news\", \"india\", \"dataisbeautiful\", \"AskEconomics\"\n",
    "    ]\n",
    "    \n",
    "    # Keywords to check for relevance in the financial context\n",
    "    finance_terms = ['market', 'stock', 'invest', 'price', 'share', 'trading',\n",
    "                     'finance', 'dividend', 'bull', 'bear', 'crypto', 'quarter',\n",
    "                     'earnings', 'portfolio', 'economy', 'fiscal', 'trend', 'growth',\n",
    "                     'profit', 'loss', 'debt', 'revenue', 'valuation', 'forecast',\n",
    "                     'analysis', 'sector', 'fund', 'etf', 'index', 'inflation']\n",
    "    \n",
    "    # Counter to track most active subreddits for this keyword\n",
    "    subreddit_count = Counter()\n",
    "    total_processed = 0\n",
    "    post_dates = []  # To track post date distribution\n",
    "    \n",
    "    try:\n",
    "        for sub in subreddits:\n",
    "            print(f\"📬 Searching r/{sub}...\")\n",
    "            try:\n",
    "                # Use Reddit's time filter for initial filtering\n",
    "                search_results = reddit.subreddit(sub).search(\n",
    "                    f'\"{keyword}\"', \n",
    "                    sort='relevance', \n",
    "                    time_filter=time_filter, \n",
    "                    limit=limit\n",
    "                )\n",
    "                \n",
    "                for submission in search_results:\n",
    "                    total_processed += 1\n",
    "                    \n",
    "                    # Get submission date\n",
    "                    post_date = datetime.fromtimestamp(submission.created_utc)\n",
    "                    \n",
    "                    # Apply date filter if specified\n",
    "                    if start_date and post_date < start_date:\n",
    "                        continue\n",
    "                    if end_date and post_date > end_date:\n",
    "                        continue\n",
    "                        \n",
    "                    # Track post date for analytics\n",
    "                    post_dates.append(post_date)\n",
    "                    \n",
    "                    # Skip low quality posts\n",
    "                    if submission.score < min_score:\n",
    "                        continue\n",
    "                    \n",
    "                    # Get basic post info\n",
    "                    title = submission.title\n",
    "                    selftext = submission.selftext if hasattr(submission, 'selftext') else \"\"\n",
    "                    url = submission.url\n",
    "                    score = submission.score\n",
    "                    created = post_date.strftime('%Y-%m-%d')\n",
    "                    \n",
    "                    # Get top comments for additional context\n",
    "                    comments = []\n",
    "                    submission.comments.replace_more(limit=0)\n",
    "                    for comment in submission.comments[:3]:  # Top 3 comments\n",
    "                        if comment.score > 1:  # Only include comments with upvotes\n",
    "                            comments.append(comment.body)\n",
    "                    \n",
    "                    # Combine all text for sentiment analysis\n",
    "                    full_content = f\"{title}. {selftext}\"\n",
    "                    comment_text = \" \".join(comments)\n",
    "                    \n",
    "                    # Check if the keyword is actually present\n",
    "                    if keyword.lower() not in (full_content + comment_text).lower():\n",
    "                        continue\n",
    "                    \n",
    "                    # Check for finance relevance (if not in primary finance subreddit)\n",
    "                    primary_finance_subs = [\"investing\", \"stocks\", \"wallstreetbets\", \"IndiaInvestments\", \n",
    "                                           \"cryptocurrency\", \"economy\", \"finance\"]\n",
    "                    if sub not in primary_finance_subs:\n",
    "                        # Check if any finance term exists in the content\n",
    "                        has_finance_term = any(term in (full_content + comment_text).lower() for term in finance_terms)\n",
    "                        if not has_finance_term:\n",
    "                            continue\n",
    "                    \n",
    "                    # Calculate sentiment\n",
    "                    title_sentiment = analyze_sentiment(title)\n",
    "                    content_sentiment = analyze_sentiment(full_content)\n",
    "                    comment_sentiment = analyze_sentiment(comment_text) if comment_text else 0\n",
    "                    \n",
    "                    # Average sentiment with weights - title matters more\n",
    "                    weighted_sentiment = (title_sentiment * 0.4 + \n",
    "                                         content_sentiment * 0.3 + \n",
    "                                         comment_sentiment * 0.3)\n",
    "                    \n",
    "                    # Calculate engagement score\n",
    "                    engagement = submission.score + (len(comments) * 2)\n",
    "                    \n",
    "                    # Extract post flair if available\n",
    "                    flair = submission.link_flair_text if hasattr(submission, 'link_flair_text') else None\n",
    "                    \n",
    "                    # Save post data\n",
    "                    post_data = {\n",
    "                        \"title\": title,\n",
    "                        \"content\": full_content[:300] + \"...\" if len(full_content) > 300 else full_content,\n",
    "                        \"subreddit\": sub,\n",
    "                        \"sentiment\": round(weighted_sentiment, 2),\n",
    "                        \"score\": score,\n",
    "                        \"comments\": len(submission.comments),\n",
    "                        \"url\": url,\n",
    "                        \"date\": created,\n",
    "                        \"engagement\": engagement,\n",
    "                        \"flair\": flair\n",
    "                    }\n",
    "                    \n",
    "                    posts.append(post_data)\n",
    "                    subreddit_count[sub] += 1\n",
    "                    \n",
    "                # Sleep briefly to avoid hitting rate limits\n",
    "                time.sleep(0.1)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error in r/{sub}: {e}\")\n",
    "                continue\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching Reddit posts: {e}\")\n",
    "    \n",
    "    # Sort by engagement and sentiment (most engaging and positive/negative first)\n",
    "    posts.sort(key=lambda x: (x[\"engagement\"], abs(x[\"sentiment\"])), reverse=True)\n",
    "    \n",
    "    print(f\"\\n✅ Processed {total_processed} Reddit posts, found {len(posts)} relevant results\")\n",
    "    \n",
    "    if post_dates:\n",
    "        earliest = min(post_dates).strftime('%Y-%m-%d')\n",
    "        latest = max(post_dates).strftime('%Y-%m-%d')\n",
    "        print(f\"📅 Posts date range: {earliest} to {latest}\")\n",
    "    \n",
    "    print(f\"🏆 Most active subreddits: {', '.join([f'r/{sub}' for sub, count in subreddit_count.most_common(3)])}\")\n",
    "    \n",
    "    return posts\n",
    "\n",
    "def extract_key_phrases(posts, keyword):\n",
    "    \"\"\"Extract recurring themes and related terms from posts\"\"\"\n",
    "    # Simple word frequency analysis to find related terms\n",
    "    all_text = \" \".join([post[\"title\"] + \" \" + post[\"content\"] for post in posts])\n",
    "    words = all_text.lower().split()\n",
    "    \n",
    "    # Filter words to remove common ones and keep only relevant\n",
    "    stopwords = [\"the\", \"a\", \"an\", \"in\", \"on\", \"at\", \"for\", \"with\", \"by\", \"to\", \n",
    "                \"of\", \"is\", \"are\", \"was\", \"were\", \"and\", \"this\", \"that\", \"it\", \"from\",\n",
    "                \"will\", \"would\", \"could\", \"should\", \"have\", \"has\", \"had\", \"been\",\n",
    "                \"their\", \"there\", \"they\", \"them\", \"these\", \"those\", \"then\", \"than\",\n",
    "                \"but\", \"not\", \"what\", \"which\", \"who\", \"when\", \"where\", \"why\", \"how\"]\n",
    "    \n",
    "    filtered_words = [w for w in words if len(w) > 3 and w not in stopwords \n",
    "                     and w != keyword.lower() and w not in keyword.lower().split()]\n",
    "    \n",
    "    # Get top terms\n",
    "    word_counts = Counter(filtered_words)\n",
    "    return word_counts.most_common(15)\n",
    "\n",
    "def extract_topics(posts):\n",
    "    \"\"\"Extract common topics from posts using flairs and content analysis\"\"\"\n",
    "    # Get flairs\n",
    "    flairs = [post[\"flair\"] for post in posts if post.get(\"flair\")]\n",
    "    flair_counter = Counter(flairs)\n",
    "    \n",
    "    # Extract topics from titles using simplistic approach\n",
    "    topics = []\n",
    "    common_title_patterns = [\n",
    "        \"about\", \"regarding\", \"on\", \"for\", \"vs\", \"versus\", \"and\", \"-\", \":\"\n",
    "    ]\n",
    "    \n",
    "    for post in posts:\n",
    "        title = post[\"title\"].lower()\n",
    "        \n",
    "        # Look for patterns like \"X vs Y\" or \"About X\"\n",
    "        for pattern in common_title_patterns:\n",
    "            if pattern in title:\n",
    "                parts = title.split(pattern)\n",
    "                if len(parts) >= 2:\n",
    "                    for part in parts:\n",
    "                        clean_part = part.strip()\n",
    "                        if len(clean_part) > 3 and clean_part not in topics:\n",
    "                            topics.append(clean_part)\n",
    "    \n",
    "    return flair_counter.most_common(5), topics[:10]\n",
    "\n",
    "def analyze_sentiment_trends(posts):\n",
    "    \"\"\"Analyze sentiment trends over time\"\"\"\n",
    "    # Group posts by date\n",
    "    date_sentiment = {}\n",
    "    for post in posts:\n",
    "        date = post[\"date\"]\n",
    "        sentiment = post[\"sentiment\"]\n",
    "        \n",
    "        if date not in date_sentiment:\n",
    "            date_sentiment[date] = []\n",
    "        \n",
    "        date_sentiment[date].append(sentiment)\n",
    "    \n",
    "    # Calculate average sentiment per day\n",
    "    daily_sentiment = {date: sum(sentiments)/len(sentiments) \n",
    "                      for date, sentiments in date_sentiment.items()}\n",
    "    \n",
    "    # Sort by date\n",
    "    sorted_dates = sorted(daily_sentiment.keys())\n",
    "    trend_data = [(date, daily_sentiment[date]) for date in sorted_dates]\n",
    "    \n",
    "    return trend_data\n",
    "\n",
    "def summarize_reddit_insights(posts, keyword):\n",
    "    \"\"\"Generate comprehensive insights from Reddit data\"\"\"\n",
    "    if not posts:\n",
    "        print(\"\\n❌ No relevant Reddit posts found\")\n",
    "        return\n",
    "    \n",
    "    # Calculate sentiment distribution\n",
    "    sentiments = [post[\"sentiment\"] for post in posts]\n",
    "    positive = sum(1 for s in sentiments if s > 0.1)\n",
    "    negative = sum(1 for s in sentiments if s < -0.1)\n",
    "    neutral = len(sentiments) - positive - negative\n",
    "    \n",
    "    avg_sentiment = sum(sentiments) / len(sentiments) if sentiments else 0\n",
    "    \n",
    "    # Extract sentiment trend\n",
    "    sentiment_trend = analyze_sentiment_trends(posts)\n",
    "    trend_direction = \"⬆️ IMPROVING\" if len(sentiment_trend) > 1 and sentiment_trend[-1][1] > sentiment_trend[0][1] else \"⬇️ DECLINING\" if len(sentiment_trend) > 1 and sentiment_trend[-1][1] < sentiment_trend[0][1] else \"➡️ STABLE\"\n",
    "    \n",
    "    # Extract common themes\n",
    "    key_terms = extract_key_phrases(posts, keyword)\n",
    "    \n",
    "    # Extract topics\n",
    "    flairs, topics = extract_topics(posts)\n",
    "    \n",
    "    # Identify most active communities\n",
    "    community_activity = Counter([post[\"subreddit\"] for post in posts])\n",
    "    top_communities = community_activity.most_common(5)\n",
    "    \n",
    "    # Print comprehensive summary\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(f\"📊 MARKET INSIGHT SUMMARY: '{keyword.upper()}'\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Overall sentiment summary\n",
    "    print(f\"\\n🌡️ SENTIMENT ANALYSIS:\")\n",
    "    sentiment_label = \"BULLISH\" if avg_sentiment > 0.2 else \"BEARISH\" if avg_sentiment < -0.2 else \"NEUTRAL\"\n",
    "    print(f\"- Overall market sentiment: {avg_sentiment:.2f} [{sentiment_label}]\")\n",
    "    print(f\"- Sentiment trend: {trend_direction}\")\n",
    "    print(f\"- Distribution: {positive} positive ({positive/len(posts)*100:.1f}%), {neutral} neutral ({neutral/len(posts)*100:.1f}%), {negative} negative ({negative/len(posts)*100:.1f}%)\")\n",
    "    \n",
    "    # Key communities and topics\n",
    "    print(f\"\\n🏙️ KEY COMMUNITIES:\")\n",
    "    for sub, count in top_communities:\n",
    "        sub_posts = [p for p in posts if p[\"subreddit\"] == sub]\n",
    "        sub_sentiment = sum(p[\"sentiment\"] for p in sub_posts) / len(sub_posts)\n",
    "        print(f\"- r/{sub}: {count} posts | Sentiment: {sub_sentiment:.2f}\")\n",
    "    \n",
    "    # Main topics and themes\n",
    "    print(f\"\\n🔑 KEY THEMES & RELATED TERMS:\")\n",
    "    print(f\"- {', '.join([term[0] for term in key_terms[:10]])}\")\n",
    "    \n",
    "    if flairs:\n",
    "        print(f\"\\n🏷️ COMMON POST CATEGORIES:\")\n",
    "        for flair, count in flairs:\n",
    "            print(f\"- {flair}: {count} posts\")\n",
    "    \n",
    "    # Overall market assessment\n",
    "    print(f\"\\n📈 MARKET ASSESSMENT:\")\n",
    "    if avg_sentiment > 0.2:\n",
    "        print(\"- The market appears POSITIVE on this topic\")\n",
    "        print(\"- Investors seem optimistic and discussions show confidence\")\n",
    "    elif avg_sentiment < -0.2:\n",
    "        print(\"- The market appears NEGATIVE on this topic\")\n",
    "        print(\"- Investors express concern and discussions show caution\")\n",
    "    else:\n",
    "        print(\"- The market appears MIXED/NEUTRAL on this topic\")\n",
    "        print(\"- Investors have varied opinions with no strong consensus\")\n",
    "    \n",
    "    # Additional insights based on content analysis\n",
    "    bullish_terms = [\"growth\", \"rally\", \"opportunity\", \"undervalued\", \"buy\", \"bullish\"]\n",
    "    bearish_terms = [\"risk\", \"overvalued\", \"crash\", \"sell\", \"bearish\", \"caution\"]\n",
    "    \n",
    "    all_content = \" \".join([p[\"title\"] + \" \" + p[\"content\"] for p in posts]).lower()\n",
    "    \n",
    "    bull_mentions = sum(all_content.count(term) for term in bullish_terms)\n",
    "    bear_mentions = sum(all_content.count(term) for term in bearish_terms)\n",
    "    \n",
    "    if bull_mentions > bear_mentions * 1.5:\n",
    "        print(\"- Bullish sentiment significantly outweighs bearish views\")\n",
    "    elif bear_mentions > bull_mentions * 1.5:\n",
    "        print(\"- Bearish sentiment significantly outweighs bullish views\")\n",
    "    else:\n",
    "        print(\"- Mixed bull/bear sentiment suggests uncertainty\")\n",
    "    \n",
    "    # Show top posts by sentiment category\n",
    "    print(\"\\n\" + \"-\"*60)\n",
    "    print(\"📝 NOTABLE DISCUSSIONS\")\n",
    "    print(\"-\"*60)\n",
    "    \n",
    "    print(\"\\n🟢 TOP POSITIVE DISCUSSIONS:\")\n",
    "    positive_posts = sorted([p for p in posts if p[\"sentiment\"] > 0.1], \n",
    "                           key=lambda x: x[\"sentiment\"], reverse=True)[:3]\n",
    "    for i, post in enumerate(positive_posts, 1):\n",
    "        print(f\"  {i}. r/{post['subreddit']} | {post['date']} | ⬆️ {post['score']} | 💬 {post['comments']} | 😀 {post['sentiment']}\")\n",
    "        print(f\"     {post['title']}\")\n",
    "    \n",
    "    print(\"\\n🔴 TOP NEGATIVE DISCUSSIONS:\")\n",
    "    negative_posts = sorted([p for p in posts if p[\"sentiment\"] < -0.1], \n",
    "                           key=lambda x: x[\"sentiment\"])[:3]\n",
    "    for i, post in enumerate(negative_posts, 1):\n",
    "        print(f\"  {i}. r/{post['subreddit']} | {post['date']} | ⬆️ {post['score']} | 💬 {post['comments']} | 😡 {post['sentiment']}\")\n",
    "        print(f\"     {post['title']}\")\n",
    "    \n",
    "    print(\"\\n📈 MOST ENGAGING DISCUSSIONS:\")\n",
    "    engaging_posts = sorted(posts, key=lambda x: x[\"engagement\"], reverse=True)[:5]\n",
    "    for i, post in enumerate(engaging_posts, 1):\n",
    "        print(f\"  {i}. r/{post['subreddit']} | {post['date']} | ⬆️ {post['score']} | 💬 {post['comments']} | {post['sentiment']:.2f}\")\n",
    "        print(f\"     {post['title']}\")\n",
    "    \n",
    "    # Conclusion and recommendation\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"💡 CONCLUSION\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    if avg_sentiment > 0.3:\n",
    "        print(f\"The market sentiment on {keyword} is strongly POSITIVE. Community discussions indicate high confidence.\")\n",
    "    elif avg_sentiment > 0.1:\n",
    "        print(f\"The market sentiment on {keyword} is moderately POSITIVE. Discussions show cautious optimism.\")\n",
    "    elif avg_sentiment < -0.3:\n",
    "        print(f\"The market sentiment on {keyword} is strongly NEGATIVE. Community discussions express significant concern.\")\n",
    "    elif avg_sentiment < -0.1:\n",
    "        print(f\"The market sentiment on {keyword} is moderately NEGATIVE. Discussions indicate caution.\")\n",
    "    else:\n",
    "        print(f\"The market sentiment on {keyword} is NEUTRAL or MIXED. No clear consensus has emerged.\")\n",
    "\n",
    "def parse_date(date_str):\n",
    "    \"\"\"Parse date string into datetime object\"\"\"\n",
    "    try:\n",
    "        # Try various formats\n",
    "        formats = [\n",
    "            '%Y-%m-%d',\n",
    "            '%d/%m/%Y',\n",
    "            '%m/%d/%Y',\n",
    "            '%d-%m-%Y',\n",
    "            '%m-%d-%Y',\n",
    "            '%d %b %Y',\n",
    "            '%b %d %Y'\n",
    "        ]\n",
    "        \n",
    "        for fmt in formats:\n",
    "            try:\n",
    "                return datetime.strptime(date_str, fmt)\n",
    "            except ValueError:\n",
    "                continue\n",
    "        \n",
    "        # If no format works, raise exception\n",
    "        raise ValueError(f\"Couldn't parse date: {date_str}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error parsing date: {e}\")\n",
    "        return None\n",
    "\n",
    "# ----------- MAIN WORKFLOW -----------\n",
    "def get_market_insights(query, start_date=None, end_date=None):\n",
    "    \"\"\"Get market insights for a query within a date range\"\"\"\n",
    "    print(f\"\\n🔎 Researching market insights for: '{query}'\")\n",
    "    \n",
    "    # Parse dates if provided\n",
    "    start_date_obj = parse_date(start_date) if start_date else None\n",
    "    end_date_obj = parse_date(end_date) if end_date else None\n",
    "    \n",
    "    # Fetch and analyze Reddit posts\n",
    "    reddit_posts = fetch_reddit(query, start_date_obj, end_date_obj)\n",
    "    \n",
    "    # Summarize Reddit insights\n",
    "    summarize_reddit_insights(reddit_posts, query)\n",
    "    \n",
    "    return reddit_posts\n",
    "\n",
    "# ----------- Run Example -----------\n",
    "if __name__ == '__main__':\n",
    "    print(\"🚀 MARKET SENTIMENT ANALYZER 🚀\")\n",
    "    print(\"-----------------------------------\")\n",
    "    user_query = input(\"Enter market topic to research: \")\n",
    "    \n",
    "    # Optional date filtering\n",
    "    use_dates = input(\"Filter by date range? (y/n): \").lower() == 'y'\n",
    "    \n",
    "    if use_dates:\n",
    "        start_date = input(\"Enter start date (YYYY-MM-DD or leave blank for none): \")\n",
    "        end_date = input(\"Enter end date (YYYY-MM-DD or leave blank for none): \")\n",
    "        \n",
    "        # Handle empty inputs\n",
    "        start_date = start_date if start_date.strip() else None\n",
    "        end_date = end_date if end_date.strip() else None\n",
    "        \n",
    "        get_market_insights(user_query, start_date, end_date)\n",
    "    else:\n",
    "        get_market_insights(user_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "719f4ffa-997f-4e6f-987e-9de4fbbb9dd3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
